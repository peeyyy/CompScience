# Linear Regression (House Price Predictor) - **Laboratory Exercise 01**

A simple **Linear Regression** tool using **NumPy, Matplotlib, and Tkinter**.  
It predicts house prices based on size and computes:

-  **Slope (m)**
-  **Intercept (b)**
-  **Mean Squared Error (MSE)**
-  **Coefficient of Determination (RÂ²)**
-  **Regression Line Plot**
-  **Residual Plot**

# Naive Bayes Classifier (Car Status Predictor) - **Laboratory Exercise 02**
This program uses a Naive Bayes classifier to predict whether a car is "Old" or "New" based on its features: color, brand, and gasoline type. Users input the car's details, and the program validates the input before making a prediction. It allows for continuous predictions until the user decides to exit.

# k-Nearest Neighbors (k-NN) - **Laboratory Exercise 03**
The k-Nearest Neighbors (k-NN) algorithm is a supervised learning method used for classification. In the program, the user inputs data points along with their class labels, and the algorithm calculates the distance (using the given formula) between the new point and all existing points. The k nearest neighbors are selected, and the majority class among them determines the class of the new point. It also includes an ASCII graph to visualize the results.

# k-Means Clustering

The k-Means clustering algorithm is an unsupervised learning method that groups data points into k clusters based on similarity. It starts by selecting k initial centroids (first k points in your case), then assigns each data point to the nearest centroid using the given distance formula. The centroids are then updated based on the mean of assigned points, and this process repeats until the centroids stabilize. It has an ASCII graph visualization of the final clusters and centroids.


# EJ Faye Dulay (2 - BSCS - A)
**Laboratory Exercises - Computational Science**

